Is to recollect data from a website via a software, a web spider will start with some website and it will be following the hyperlinks. 

### Web spider in browsers
The browser utilizes this technique to index several pages, basically filtering by the metadata from the websites, such as the meta tags in the head of the html. This bot of web scraping has a [bias](https://en.wikipedia.org/wiki/Algorithmic_bias), as more visits, and more hyperlinks has a website as highest is in the SEO, but also affects [vital cores](https://vercel.com/blog/how-core-web-vitals-affect-seo).
The crawler bot utilize the robots.txt file, to see what page could be indexed, which is a literally a txt, with instructions as the user agent value, and an allow followed by the URL allowed to index, and a disallow for the urls that aren't allowed for indexing

### Scraping
Scrapping on the other hand, didn't follow this rules, and decide to download websites, sometimes for the same website. The mitigation to this is to change data regurarly, rate limit and CAPTCHA
https://www.cloudflare.com/learning/bots/what-is-data-scraping/